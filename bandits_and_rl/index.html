<!DOCTYPE html>
<html>
<head>
    <title>Bandits &amp; RL</title>
    <script src="tabcontent.js" type="text/javascript"></script>
    <link href="template2/tabcontent.css" rel="stylesheet" type="text/css" />
	<style type="text/css">
	.auto-style1 {
		margin-top: 47;
	}
	.auto-style2 {
	text-align: center;
}

.content {
  color: #222222;
  font: 11pt Helvetica, Arial, sans-serif;
  text-decoration : none;
  padding-top: 10pt;
  padding-bottom: 10pt;
  padding-left: 10pt;
  padding-right: 15pt;
  text-align: left;
}

	</style>
</head>
<body style="background:#F6F9FC; font-family:Arial;">
<h3 class="auto-style2">Bandits and Reinforcement Learning (COMS E6998.001, Fall 2017)</h3>
&nbsp;<div style="width: 677px; padding: 0px 0 40px; margin-left: auto; margin-right: auto; margin-bottom: 0;" class="auto-style1">
        <ul class="tabs" data-persist="true">
            <li visible="true"><a href="#view1">Course Info</a></li>
            <li><a href="#view2">Lectures</a></li>
			<li><a href="#view3">Project</a></li>
        </ul>
		<div class="tabcontents">

            <div id="view1">
            <div class="content">
                <p><strong>Instructors</strong>:
				<a href="http://alekhagarwal.net/">Alekh Agarwal</a> and
				<a href="https://www.microsoft.com/en-us/research/people/slivkins/">
				Alex Slivkins</a> (Microsoft Research NYC)<br>
				<span class="section-days"><strong>Schedule</strong>: Wednesdays</span>
				4:10-6:40pm<br><span class="class-end-time">
				<span class="class-building"><strong>Location:</strong>
				TBD<strong>.<br>Office Hours</strong>: TBD.<br><strong>Q&amp;A:</strong> 
				TBD. <strong>
				<br>Contact:</strong> 
				<a href="mailto:bandits-fa17-instr@microsoft.com">
				bandits-fa17-instr@microsoft.com</a>.</span></span></p>
				<p><span class="class-end-time"><strong>Course 
				description</strong> </span></p>
				<p><span class="class-end-time">This course covers several 
				foundational topics in sequential decision making. We start with 
				multi-armed bandits, and proceed to contextual bandits, a 
				generalization motivated by several real-world applications. We 
				cover the main algorithms, performance guarantees and lower 
				bounds, along with applications in the industry. We also discuss 
				“offline off-policy evaluation”: performance assessment 
				techniques for real-world online systems. The remainder of the 
				course concerns the more general problem of reinforcement 
				learning, from small-state MDPs to recent extensions that handle 
				large state spaces.</span></p>
				<p><strong>Prerequesites </strong></p>
				<p>Exposure to algorithms and proofs at the level of an 
				undergraduate algorithms course (CSOR 4231). Graduate ML course 
				(COMS 4771) or current enrollment therein. If you do not meet 
				these, please email the instructors. </p>
				<p><strong>Tentative topics</strong></p>
				<ul>
					<li>Fundamental algorithms for multi-armed bandits:<ul>
						<li>IID rewards: UCB1, Successive Elimination</li>
						<li>adversarial rewards: multiplicative weights, 
						follow-the-leader, EXP3/EXP4</li>
						<li>Bayesian/IID rewards: Thompson Sampling</li>
					</ul>
					</li>
					<li>Advanced topics in multi-armed bandits (*)<ul>
						<li>Lower 
						bounds</li>
						<li>structured action spaces (e.g., Lipschitz, 
						linear, combinatorial)</li>
						<li>global constraints ("bandits 
						with knapsacks")</li>
						<li>connections to game theory and 
						mechanism design</li>
					</ul>
					(*) some but not all of these topics 
						will be covered</li>
					<li>Contextual Bandits (CB)<ul>
						<li>CB 
						with classification oracle: Epsilon-greedy, "Taming the 
						Monster"</li>
						<li>CB with linear rewards: LinUCB</li>
						<li>Off-Policy 
						Evaluation</li>
					</ul>
					</li>
					<li>Reinforcement Learning<ul>
						<li>MDPs, Value 
						functions, Value Iteration, Q-Learning</li>
						<li>R-MAX, lower 
						bounds</li>
						<li>Bellman Rank and resulting algorithm<br></li>
					</ul>
					</li>
				</ul>
				<p><strong>Resources</strong></p>
				<p><strong>Coursework and assessment: </strong>a final project, 
				letter grade.</p>
            </div>
			</div>
            <div id="view2">
            	<div class="content">
				coming				
					...</div>
			</div>
			
			<div id="view3">
            <div class="content">
                
                <p>coming ... </p>
			</div>
			</div>

        </div>
    </div>
</body>
</html>
