<html>
<head>
<title> Alekh Agarwal </title>
<script type="text/javascript" src="spam.js"></script>
<META NAME="keywords" CONTENT="alekh, alekh agarwal, Alekh, Alekh Agarwal">
</head>
<body bgcolor="#fffff">
<table width=990 align=center bgcolor="#FFEFD5"r><td width=50 align=left><img src="Alekh Agarwal.jpg"><br><br></td>
<td width=600 align=left><font face=helvetica><h2>Alekh Agarwal</h2><b>Researcher</b><br><a href="http://research.microsoft.com" target="_blank">Microsoft Research, New York</a><br>
<b>Email:</b> <script>spam("alekha",1);</script><br><br>
</td></tr><br>
</table>

<table width=990 align=center><tr>
    <table width=990 align=center><tr><td width=100 align="left"><br><font size=+2 face="helvetica">About Me</font></td></tr><tr></table><hr width=990 align="center"></tr>
<tr><table width=990 align=center><tr><td width=600 align="left"><font face="helvetica">I am currently a researcher in the New York lab of Microsoft Research, where I also spent two wonderful years as a postdoc. Prior to that, I obtained my PhD in Computer Science from UC Berkeley, working with  <a href="http://www.cs.berkeley.edu/~bartlett">Peter Bartlett</a> and <a href="http://www.cs.berkeley.edu/~wainwrig">Martin Wainwright</a>.</font></td></tr>


<tr><td width=600 align="left"><br><font face="helvetica"><font size=+2>Interests</font>
<hr width=990 align="center">
I am broadly interested in <b>Machine Learning</b>, <b>Statistics</b> and <b>Optimization</b>. My research focus is on problems which arise while applying machine learning techniques to massive datasets. Part of my research aims to understand the tradeoffs between learning and computation, as well as designing efficient learning algorithms that can learn under a given computational budget. On the algorithmic side, I am also quite interested in the design of distributed machine learning algorithms. Some of my other work considers computational and statistical aspects of estimation in high-dimensional problems. More recently, I have been looking at approaches for learning feature representations from data, in a theoretically principled and practically efficient manner. In a past life, I worked on Machine Learning applied to Web Search and Ranking. 
</tr>
<tr><td width=600 align="left"><br><font face="helvetica"><font size=+2>Publications</font>
<a name="publications"></a>
<hr width=990 align="center">
<br>
<font face="helvetica"><font size=+2>Ph.D. Thesis</font><br>
<ul>
<li><a href="thesismain.pdf">Computational Trade-offs in Statistical Learning</a>, Ph.D. Thesis, Department of Computer Science, UC Berkeley, 2012. <br><br>
</ul>
<font face="helvetica"><font size=+2>Preprints</font>
<ul>           
    <li><a href="http://arxiv.org/abs/1606.03966"> A Multiworld Testing Decision Service</a><br> with a number of wonderful Microsoft colleagues. Link to service <a href="http://mwtds.azurewebsites.net/">here</a>. More details <a href="https://www.microsoft.com/en-us/research/project/multi-world-testing-mwt/">here</a>.<br><br></li>
    <li><a href="http://arxiv.org/abs/1605.04812"> Off-policy evaluation for slate recommendation</a><br>with Adith Swaminathan, Akshay Krishnamurthy, Miro Dudik, John Langford, Damien Jose and Imed Zitouni<br>Arxiv version, In preparation<br><br></li>
    <li><a href="arxiv_geql.pdf">Exploratory Gradient Boosting for Reinforcement Learning in Complex Domains</a><br>with David Abel, Fernando Diaz, Akshay Krishnamurthy and Rob Schapire<br><a href="http://blogs.microsoft.com/next/2016/03/13/project-aix-using-minecraft-build-intelligent-technology/">Blog post</a> covering the AIX platform used for Minecraft experiments.<br><br></li>    
    <li><a href="http://arxiv.org/pdf/1310.8243v1">Para-active Learning</a><br>with Leon Bottou, Miro Dudik and John Langford<br>Arxiv version, In preparation<br><br></li>
<li><a href="multitask_techrep.pdf">Matrix Regularization techniques for online multitask learning</a><br> with Alexander Rakhlin and Peter Bartlett<br>EECS Department, University of California, Berkeley, Tech. Rep. UCB/EECS-2008-138, Oct. 2008.<br><br></li>

</ul>
<font face="helvetica"><font size=+2>Journal Publications</font>
<ul>
    <li><a href="http://arxiv.org/pdf/1310.7991v1">Learning Sparsely Used Overcomplete Dictionaries via Alternating Minimization</a><br>with Anima Anandkumar, Prateek Jain, Praneeth Netrapalli and Rashish Tandon<br>to appear in SIAM Journal of Optimization.<br><br></li>
    <li><a href="http://arxiv.org/pdf/1309.1952v1">Exact Recovery of Sparsely Used Overcomplete Dictionaries</a><br>with Anima Anandkumar and Praneeth Netrapalli<br>to appear in IEEE Transactions on Information Theory.<br><br></li>
    <li><a href="http://arxiv.org/abs/1110.4198">A Reliable Effective Terascale Linear Learning System</a><br> with Olivier Chappelle, Miroslav Dudik and John Langford<br>In Journal of Machine Learning Research, Vol. 15, 2014. <br><br></li>
    <li><a href="http://arxiv.org/abs/1110.2529">The Generalization Ability of Online Algorithms for Dependent Data</a><br>with John Duchi<br>In IEEE Transactions on Information Theory, Vol. 59, Issue 1, 2013.<br><br></li>
    <li><a href="http://arxiv.org/abs/1107.1744">Stochastic convex optimization with bandit feedback</a><br> with Dean Foster, Daniel Hsu, Sham Kakade and Alexander Rakhlin<br>In SIAM Journal on Optimization, Vol. 23, Issue 1, 2013.<br><br></li>
    <li><a href="DuchiAgJoJo12.pdf">Ergodic Mirror Descent</a><br>with John Duchi, Mikael Johansson and Mike Jordan<br>In SIAM Journal on Optimization, Vol. 22, Issue 4, 2012.<br><br></li>
    <li><a href="http://arxiv.org/abs/1104.4824">Fast global convergence of gradient methods for high-dimensional statistical recovery</a><br>with Sahand Negahban and Martin Wainwright<br>In The Annals of Statistics, Vol. 40, Number 5, 2012. <br><br></li>
    <li><a href="http://arxiv.org/abs/1102.4807">Noisy matrix decomposition via convex relaxation: Optimal rates in high dimensions</a>&nbsp;&nbsp;<a href="AOS1000.pdf">(Annals formatted version)</a><br>with Sahand Negahban and Martin Wainwright<br>In The Annals of Statistics, Vol. 40, Number 2, July 2012.<br><br></li>
    <li><a href="CameraReady_IEEE.pdf">Information-theoretic lower bounds on the oracle complexity of stochastic convex optimization</a><br>with Peter Bartlett, Pradeep Ravikumar and Martin Wainwright<br>In IEEE Transcations on Information Theory, Vol 58, Issue 5, May 2012.<br><br></li>
    <li><a href="dist_notes_ieee.pdf">Dual Averaging for Distributed Optimization: Convergence Analysis and Network Scaling</a><br>with John Duchi and Martin Wainwright<br>In IEEE Transactions on Automatic Control, Vol. 57, Issue 3, 2012.<br><br></li>
<li><a href="ravikumar10b.pdf">Message-passing for graph structured linear programs: Proximal projections, convergence and rounding schemes</a><br> with Pradeep Ravikumar and Martin Wainwright<br> In Journal Of Machine Learning Research, Vol. 11, 2010.<br><br></li>
</ul>
<font face="helvetica"><font size=+2>Conference Publications</font>
<ul>
         <li><a href="http://arxiv.org/abs/1602.02722"> Contextual-MDPs for PAC-Reinforcement Learning with Rich Observations</a><br>with Akshay Krishnamurthy and John Langford<br>In NIPS 2016<br><br></li>
         <li><a href="http://arxiv.org/abs/1602.02202">Efficient Second Order Online Learning by Sketching</a><br>with Haipeng Luo, Nicolo Cesa-Bianchi and John Langford<br>In NIPS 2016<br><br></li>
         <li><a href="http://arxiv.org/abs/1502.05890">Efficient Contextual Semi-Bandit Learning</a><br>with Akshay Krishnamurthy and Miro Dudik<br>In NIPS 2016<br><br></li>
         <li><a href="http://arxiv.org/abs/1507.00407">Fast Convergence of Regularized Learning in Games</a>    (<b>Best paper award</b>)<br>with Vasilis Syrgkanis, Haipeng Luo and Rob Schapire<br>In NIPS 2015<br><br></li>
         <li><a href="http://arxiv.org/abs/1506.08669">Efficient and Parsimonious Agnostic Active Learning</a><br>with T-K Huang, Daniel Hsu, John Langford and Rob Schapire<br>In NIPS 2015<br><br></li>
         <li><a href="http://arxiv.org/abs/1502.02206">Learning to Search Better Than Your Teacher</a><br>with Kai-Wei Chang, Akshay Krishnamurthy, Hal Daum&eacute; III and John Langford<br>In ICML 2015<br><br></li>
         <li><a href="http://arxiv.org/abs/1410.0723">A Lower Bound for the Optimization of Finite Sums</a><br>with L&eacute;on Bottou<br>In ICML 2015<br><br></li>
         <li><a href="http://arxiv.org/pdf/1410.0440">Scalable Nonlinear Learning with Adaptive Polynomial Expansions</a><br>with Alina Beygelzimer, Daniel Hsu, John Langford and Matus Telgarsky<br>In NIPS 2014<br><br></li>
         <li><a href="dict-learning-colt.pdf">Learning sparsely used overcomplete dictionaries</a><br>with Anima Anandkumar, Prateek Jain, Praneeth Netrapalli and Rashish Tandon<br>In COLT 2014<br><br></li>
         <li><a href="manager.pdf">Robust Multi-Objective Learning with Mentor Feedback</a><br>with Ashwinkumar BV, Miro Dudik, Rob Schapire and Alex Slivkins<br>In COLT 2014<br><br></li>
         <li><a href="http://arxiv.org/abs/1402.0555">Taming the Monster: A Fast and Simple Algorithm for Contextual Bandits</a><br>with Daniel Hsu, Satyen Kale, John Langford, Lihong Li and Rob Schapire<br>In ICML 2014<br><br></li>
         <li><a href="http://arxiv.org/pdf/1310.1949v2">Least Squares Revisited: Scalable Approaches for Multi-class Prediction</a><br>with Sham Kakade, Nikos Karampatziakis, Le Song and Greg Valiant<br>In ICML 2014<br><br></li> 
         <li><a href="multiclass.pdf">Selective sampling algorithms for cost-sensitive multiclass prediction</a> (long version with proofs)<br>In ICML 2013<br><br></li>
         <li><a href="http://arxiv.org/abs/1207.4421">Stochastic optimization and sparse statistical recovery: An optimal algorithm for high dimensions</a>  (<a href="http://arxiv.org/abs/1207.4421">Long version</a>)<br>with Sahand Negahban and Martin Wainwright<br>In NIPS 2012<br><br></li>
         <li><a href="http://arxiv.org/abs/1202.1334">Contextual Bandit Learning with Predictable Rewards</a><br> with Miroslav Dudik, Satyen Kale, John Langford and Robert Schapire<br> In AISTATS 2012<br><br></li>
         <li><a href="http://arxiv.org/abs/1107.1744">Stochastic convex optimization with bandit feedback</a><br> with Dean Foster, Daniel Hsu, Sham Kakade and Alexander Rakhlin<br>In NIPS 2011<br><br></li>
         <li><a href="http://arxiv.org/abs/1104.5525">Distributed Delayed Stochastic Optimization</a>  (<a href="http://arxiv.org/abs/1104.5525">Long version</a>)<br>with John Duchi<br>In NIPS 2011<br><br></li>
         <li><a href="http://arxiv.org/abs/1105.4681">Ergodic Subgradient Descent</a><br>with John Duchi, Mikael Johansson and Mike Jordan<br>In Allerton 2011 <br><br></li>
         <li><a href="http://eecs.berkeley.edu/~arostami/papers/corrupted_features.pdf">Learning with Missing Features</a><br>with Afshin Rostamizadeh and Peter Bartlett<br>In UAI 2011 <br><br></li>
         <li><a href="http://jmlr.csail.mit.edu/proceedings/papers/v19/agarwal11a/agarwal11a.pdf">Oracle inequalities for computationally budgeted model selection</a>  (<a href="http://arxiv.org/abs/1208.0129">Long version</a>)<br>with John Duchi, Peter Bartlett and Clement Levrard<br>In COLT 2011 <br><br></li>
         <li><a href="http://arxiv.org/abs/1102.4807">Noisy matrix decomposition via convex relaxation: Optimal rates in high dimensions</a><br>with Sahand Negahban and Martin Wainwright<br>In ICML 2011 <br><br></li>         
        <li><a href="distopt_nips.pdf">DIStributed Dual Averaging In Networks</a><br>with John Duchi and Martin Wainwright<br>In NIPS 2010.<br><br></li>
	<li><a href="sparseopt_nips.pdf">Convergence rates of gradient methods for high-dimensional statistical recovery</a><br>with Sahand Negahban and Martin Wainwright<br>In NIPS 2010.<br><br></li>
        <li><a href="bandits-colt.pdf">Optimal Algorithms for Online Convex Optimization with Multi-Point Bandit Feedback</a> (longer version with additional proofs)<br>with Ofer Dekel and Lin Xiao<br>In COLT 2010.<br><br></li>
	<li><a href="300_paper.pdf">Optimal Allocation Strategies for the Dark Pool Problem</a><br> with Peter Bartlett and Max Dama<br>In AISTATS 2010.<br><br></li>
	<li><a href="1005_paper.pdf">Information-theoretic lower bounds on the oracle complexity of convex optimization</a><br>with Peter Bartlett, Pradeep Ravikumar and Martin Wainwright<br>In NIPS 2009.<br><br></li>
	<li><a href="http://arxiv.org/abs/0903.5328">A Stochastic View of Optimal Regret through Minimax Duality</a><br>with Jake Abernethy, Alexander Rakhlin and Peter Bartlett<br>arXiv preprint, short version appeared in COLT 2009.<br><br></li>	
	<li><a href="I_prox08_tech.pdf">Message-passing for graph structured linear programs: Proximal projections, convergence and rounding schemes</a><br> with Pradeep Ravikumar and Martin Wainwright<br>In ICML 2008.<br><br></li>
<li><a href="http://books.nips.cc/papers/files/nips20/NIPS2007_0780.pdf">An Analysis of Inference with the Universum</a><br>with Fabian Sinze, Olivier Chapelle and Bernhard Sch&ouml;lkopf<br>In <a href="http://www.nips.cc/">NIPS 2007</a><br><br></li>
<li><a href="http://www.cse.iitb.ac.in/~soumen/doc/netrank">Learning Random Walks to Rank Nodes in Graphs</a><br>with Soumen Chakrabarti<br>In <a href="http://oregonstate.edu/conferences/icml2007/">ICML 2007</a><br><br></li>
<li><a href="http://www.cse.iitb.ac.in/~soumen/doc/netrank">Learning Parameters in Entity-relationship Graphs from Ranking Preferences<br></a>with Soumen Chakrabarti<br>
In <a href="http://www.ecmlpkdd2006.org/"> ECML/PKDD 2006</a><br><br></li>
<li><a href="http://www.cse.iitb.ac.in/~soumen/doc/netrank">Learning to Rank Networked Entities</a><br>with Soumen Chakrabarti and Sunny Aggarwal<br>
In <a href="http://www.kdd2006.com/"> SIGKDD 2006</a><br><br></li>
</ul>
<tr><td width=600 align="left"><br><font face="helvetica"><font size=+2>Professional Activities</font>
<a name="professional"></a>
<hr width=990 align="center">
<br>
Fundraising Chair for <a href="http://aistats.org/">AISTATS 2016.</a>
<br>
Co-organized NIPS 2015 workshop on <a href="http://opt-ml.org/">Optimization for Machine Learning</a>.
<br>
Co-organized NIPS 2014 workshop on <a href="http://opt-ml.org/">Optimization for Machine Learning</a>.
<br>
Co-organized NIPS 2013 workshop on <a href="http://opt-ml.org/">Optimization for Machine Learning</a>.
<br>
Co-organized NIPS 2013 workshop on <a href="http://opt.kyb.tuebingen.mpg.de/index.html">Optimization for Machine Learning</a>.
<br>
Co-organized NIPS 2012 workshop on <a href="http://opt.kyb.tuebingen.mpg.de/index.html">Optimization for Machine Learning</a>.
<br>
Co-organized NIPS 2011 workshop on <a href="https://sites.google.come/site/costnips">Computational Trade-offs in Statistical Learning</a>.
<br>
Co-organized NIPS 2010 workshop <a href="http://lccc.eecs.berkeley.edu">Learning on Cores, Clusters and Clouds</a>.
<br>
<b>Area chair or equivalent:</b> NIPS 2016, ICML 2016, ICML 2015, COLT 2015, ICML 2013, COLT 2013, AISTATS 2013, NIPS 2013.
<br>
<b>Journal Reviewing:</b> JMLR, Annals of Statistics, IEEE Transcations on Automatic Control, IEEE Transcations on Info Theory, SIAM Journal on Optimization, Machine Learning. <br><br>
</body>

<!--footer code begin-->
<div style="font-family: Verdana; width:1002px; height:25px; padding-top:5px; font-size:60%;">
<a href="/c/1060" style="border-right:1px solid #bbb; padding:0em 1em 0em 0em;">Contact</a>
<a href="/c/1061" style="border-right:1px solid #bbb; padding:0em 1em 0em 1em;">Terms</a>
<a href="/c/1062" style="border-right:1px solid #bbb; padding:0em 1em 0em 1em;">Trademarks</a>
<a href="/c/1063" style="border-right:1px solid #bbb; padding:0em 1em 0em 1em;">Privacy and Cookies</a>
<a href="/c/1065" style="padding:0em 1em 0em 1em;">Code of Conduct</a>
<span style="margin-right:100px;">&copy;<span id="copyrightYear"></span> Microsoft Corporation. All rights reserved.</span><a href="/c/1064"><img style="margin-right:10px;" alt="Microsoft" src="/a/i/c/logo_ms.png" border="0"></a>
<script language="javascript" src="/a/year.js" type="text/javascript"></script>
</div>
<!--footer code end-->
</html>

